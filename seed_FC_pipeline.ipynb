{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#from nipype import config\n",
    "#config.enable_provenance()\n",
    "\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio\n",
    "\n",
    "from nipype import Workflow, Node, MapNode, Function, IdentityInterface\n",
    "from nipype import DataGrabber, DataSink\n",
    "from nipype.interfaces.fsl import (Merge, FLAMEO, ContrastMgr, GLM,\n",
    "                                   SmoothEstimate, Cluster, ImageMaths, MultipleRegressDesign,\n",
    "                                   MultiImageMaths)\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.interfaces.utility as util\n",
    "from nipype.interfaces.fsl.maths import BinaryMaths\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_rsfmri_glm(rsfmri_dir, analysis_dir, output_dir):\n",
    "    wf = Workflow(name='rsfmri')\n",
    "    wf.base_dir = work_dir\n",
    "    \n",
    "    def csv_to_glm():\n",
    "        import pandas as pd\n",
    "        ev_file = pd.read_csv(os.path.join(analysis_dir, 'design', 'design.csv'),\n",
    "                          index_col=0, sep=',|\\t| ', engine='python')\n",
    "        regressors = ev_file.to_dict(orient='list')\n",
    "            \n",
    "        contrast_file = pd.read_csv(os.path.join(analysis_dir, 'design', 'contrasts.csv'),\n",
    "                                index_col=0, sep=',|\\t| ', engine='python')\n",
    "        \n",
    "        ev_list = contrast_file.columns.tolist()\n",
    "        \n",
    "        contrasts = []\n",
    "        for contrast in contrast_file.index.tolist():\n",
    "            contrast_vec = contrast_file.loc[contrast].values.tolist()\n",
    "            con = [contrast, 'T', ev_list, contrast_vec]\n",
    "            contrasts.append(con)\n",
    "        num_contrasts = len(contrasts)\n",
    "\n",
    "        return regressors, contrasts, num_contrasts\n",
    "\n",
    "    regressors, contrasts, num_contrasts = csv_to_glm()\n",
    "    \n",
    "    subj_df = pd.read_csv(os.path.join(analysis_dir, 'sub_list.txt'), header=None, index_col=0)\n",
    "    sub_list = subj_df.index.tolist()\n",
    "    num_subs = len(sub_list)\n",
    "\n",
    "    infosource = Node(IdentityInterface(fields=['subject_id']),\n",
    "                        name='infosource')\n",
    "\n",
    "    infosource.iterables = [('subject_id', sub_list)]\n",
    "\n",
    "    datagrabber = Node(DataGrabber(infields=['subject_id'],\n",
    "                                    outfields=['rest_ts_smooth', 'parc_summary', 'meants']),           \n",
    "                       name='datagrabber')\n",
    "\n",
    "    datagrabber.inputs.base_directory = rsfmri_dir\n",
    "    datagrabber.inputs.template = '*'\n",
    "\n",
    "    datagrabber.inputs.field_template = {'rest_ts_smooth': '%s/resting/timeseries/'\n",
    "                                              'target/rest_01_smooth_trans_masked.nii.gz',\n",
    "                                         'parc_summary': '%s/resting/parcellations/'\n",
    "                                              'aparc/rest_01_summary.stats',\n",
    "                                         'meants': '%s/resting/parcellations/aparc/'\n",
    "                                              'rest_01_avgwf.txt'}\n",
    "    datagrabber.inputs.template_args = {'rest_ts_smooth': [['subject_id']],\n",
    "                                        'parc_summary': [['subject_id']],\n",
    "                                        'meants': [['subject_id']]}\n",
    "    datagrabber.inputs.sort_filelist = True\n",
    "\n",
    "    wf.connect(infosource, 'subject_id', datagrabber, 'subject_id')\n",
    "    \n",
    "    roi_list = pd.read_csv(os.path.join(analysis_dir, 'rois.txt'), header=None)\n",
    "    rois = [tuple(x) for x in roi_list.values]\n",
    "    \n",
    "    def get_meants(base_dir, subject_id, roi_fs, meants, summary_file):\n",
    "        import os\n",
    "        import pandas as pd\n",
    "\n",
    "        roi_dir = os.path.join(base_dir, subject_id, 'resting', 'roi_betas', roi_fs[1])\n",
    "        if not os.path.exists(roi_dir):\n",
    "            os.makedirs(roi_dir)\n",
    "        \n",
    "        summary = pd.read_csv(summary_file, header=None, comment='#', \n",
    "                              delim_whitespace=True, index_col=0) \n",
    "        roi_idx = summary[summary[4].str.contains(roi_fs[0])].index.values\n",
    "        meants = pd.read_csv(meants, delim_whitespace=True, usecols=roi_idx-1, \n",
    "                             header=None)\n",
    "        \n",
    "        ts_filename = os.path.join(roi_dir, 'seed_ts.txt')\n",
    "        meants.to_csv(ts_filename, header=False, index=False)\n",
    "        \n",
    "        beta_filename = os.path.join(roi_dir, 'MNI_beta.nii.gz')\n",
    "        absbin_filename = os.path.join(roi_dir, 'absbin.nii.gz')\n",
    "\n",
    "        return roi_fs[1], ts_filename, beta_filename, absbin_filename\n",
    "\n",
    "    get_meants = pe.Node(Function(input_names=['base_dir', 'subject_id', 'roi_fs', \n",
    "                                                'meants', 'summary_file'],\n",
    "                                  output_names=['roi', 'meants', 'beta_fname', \n",
    "                                                'absbin_fname'],\n",
    "                                  function=get_meants),\n",
    "                         name='get_meants')\n",
    "    \n",
    "    get_meants.inputs.base_dir = rsfmri_dir    \n",
    "    get_meants.iterables = [('roi_fs', rois)]\n",
    "\n",
    "    wf.connect(infosource, 'subject_id', get_meants, 'subject_id')\n",
    "    wf.connect(datagrabber, 'meants', get_meants, 'meants')\n",
    "    wf.connect(datagrabber, 'parc_summary', get_meants, 'summary_file')\n",
    "    \n",
    "    fsl_glm = Node(fsl.GLM(demean=True), name='fsl_glm')\n",
    "\n",
    "    wf.connect(datagrabber, 'rest_ts_smooth', fsl_glm, 'in_file')\n",
    "    wf.connect(get_meants, 'meants', fsl_glm, 'design')\n",
    "    wf.connect(get_meants, 'beta_fname', fsl_glm, 'out_file')\n",
    "\n",
    "    absbin = Node(fsl.ImageMaths(op_string= '-abs -bin'), \n",
    "                  name='absbin')\n",
    "\n",
    "    wf.connect(fsl_glm, 'out_file', absbin, 'in_file')\n",
    "    wf.connect(get_meants, 'absbin_fname', absbin, 'out_file')\n",
    "\n",
    "    base = os.path.join(analysis_dir, 'base.nii.gz')\n",
    "\n",
    "    mask = pe.JoinNode(interface=fsl.MultiImageMaths(in_file=base),\n",
    "                joinsource='infosource', joinfield='operand_files', name='mask')\n",
    "\n",
    "    mask.inputs.op_string = '-add %s ' * (num_subs)\n",
    "\n",
    "    wf.connect(absbin, 'out_file', mask, 'operand_files')\n",
    "\n",
    "    merge = pe.JoinNode(interface=fsl.Merge(merged_file='merge.nii.gz', dimension='t'), \n",
    "                    joinsource='infosource', joinfield='in_files', name='merge')\n",
    "\n",
    "    wf.connect(fsl_glm, 'out_file', merge, 'in_files')\n",
    "        \n",
    "    thresh = Node(fsl.ImageMaths(op_string='-thr %s -bin' % (num_subs + 1)), \n",
    "                  name='thresh')\n",
    "        \n",
    "    wf.connect(mask, 'out_file', thresh, 'in_file')\n",
    "        \n",
    "    model = Node(fsl.MultipleRegressDesign(), name='model')\n",
    "    model.inputs.contrasts = contrasts\n",
    "    model.inputs.regressors = regressors\n",
    "        \n",
    "    flameo = Node(fsl.FLAMEO(run_mode='flame1'), name='flameo')\n",
    "        \n",
    "    wf.connect(merge, 'merged_file', flameo, 'cope_file')\n",
    "    wf.connect([(model, flameo, [('design_grp', 'cov_split_file'),\n",
    "                                 ('design_mat', 'design_file'),\n",
    "                                 ('design_con', 't_con_file')])])\n",
    "    \n",
    "    wf.connect(thresh, 'out_file', flameo, 'mask_file')\n",
    "        \n",
    "    smoothest = MapNode(fsl.SmoothEstimate(), iterfield=['zstat_file'], \n",
    "                        name='smoothest')\n",
    "        \n",
    "    wf.connect(flameo, 'zstats', smoothest, 'zstat_file')\n",
    "    wf.connect(thresh, 'out_file', smoothest, 'mask_file')\n",
    "    \n",
    "    cluster = MapNode(fsl.Cluster(out_index_file='zstat_index.nii.gz', \n",
    "                                  out_localmax_txt_file='zstat_localmax.txt',\n",
    "                                  out_localmax_vol_file='zstat_localmax.nii.gz',\n",
    "                                  out_threshold_file='zstat_thresh.nii.gz'), \n",
    "                      iterfield=['in_file', 'volume', 'dlh'], name='cluster')\n",
    "    \n",
    "    wf.connect(flameo, 'zstats', cluster, 'in_file')\n",
    "    wf.connect(smoothest, 'volume', cluster, 'volume')\n",
    "    wf.connect(smoothest, 'dlh', cluster, 'dlh')\n",
    "    \n",
    "    cluster.inputs.threshold = 2.3\n",
    "    cluster.inputs.pthreshold = 0.001\n",
    "\n",
    "        \n",
    "    def get_subs(rois, num_contrasts):\n",
    "        subs = [('base_maths_maths', 'mask_thresh')]\n",
    "\n",
    "        for roi in rois:\n",
    "            subs.append(('_roi_fs_%s.%s/' % (roi[0], roi[1]), ''))\n",
    "        \n",
    "        for i in range(num_contrasts):\n",
    "            subs.append(('_cluster%d/zstat' % i, 'zstat%d' % (i + 1)))\n",
    "\n",
    "        return subs\n",
    "\n",
    "            \n",
    "    subsgen = pe.Node(Function(input_names=['rois', 'num_contrasts'],\n",
    "                                   output_names=['substitutions'],\n",
    "                                   function=get_subs),\n",
    "                      name='subsgen')\n",
    "    \n",
    "    subsgen.inputs.rois = rois\n",
    "    subsgen.inputs.num_contrasts = num_contrasts\n",
    "    \n",
    "    datasink = pe.Node(interface=nio.DataSink(),\n",
    "                           name=\"datasink\")\n",
    "    datasink.inputs.base_directory = output_dir\n",
    "\n",
    "    wf.connect(get_meants, 'roi', datasink, 'container')\n",
    "    wf.connect(subsgen, 'substitutions', datasink, 'substitutions')\n",
    "    \n",
    "    wf.connect(merge, 'merged_file', datasink, 'qa.merged_betas')\n",
    "\n",
    "    wf.connect(thresh, 'out_file', datasink, 'qa.mask')\n",
    "    \n",
    "    wf.connect([(model, datasink,\n",
    "                        [('design_grp', 'qa.model'),\n",
    "                        ('design_mat', 'qa.model.@mat'),\n",
    "                        ('design_con', 'qa.model.@con')])])\n",
    "                \n",
    "    wf.connect([(flameo, datasink,\n",
    "                        [('copes', 'flameo'),\n",
    "                        ('pes', 'flameo.@pes'),\n",
    "                        ('var_copes', 'flameo.@varcopes'),\n",
    "                        ('zstats', 'flameo.@zstats'),\n",
    "                        ('tdof', 'flameo.@tdof'),\n",
    "                        ('tstats', 'flameo.@tstats')])])\n",
    "\n",
    "    wf.connect([(cluster, datasink,\n",
    "                        [('index_file', 'cluster.@index'),\n",
    "                        ('localmax_txt_file', 'cluster.@lmax_txt'),\n",
    "                        ('localmax_vol_file', 'cluster.@lmax_vol'),\n",
    "                        ('threshold_file', 'cluster.@thresh')])])\n",
    "    \n",
    "    return wf\n",
    "\n",
    "  \n",
    "analysis_dir = '/om/user/annepark/git_repos/EF4/group_analysis/'\n",
    "rsfmri_dir = '/om/user/annepark/git_repos/EF4/'\n",
    "output_dir = '/om/user/annepark/git_repos/EF4/group_analysis/output_dir'\n",
    "\n",
    "work_dir = os.path.join(rsfmri_dir, 'group_analysis_wd')\n",
    "wf = run_rsfmri_glm(rsfmri_dir, analysis_dir, output_dir) \n",
    "wf.write_graph()\n",
    "wf.run(plugin='SLURM')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
